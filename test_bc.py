"""
Behavior Cloning with Denoising Autoencoder

This experiment demonstrates the use of a denoising autoencoder to mitigate the covariate shift issue in behavior cloning for a simple 2D trajectory tracking task.

The main components of this experiment are:

1. Trajectory Simulation:
   A 2D sinusoidal trajectory is simulated using the `simulate_trajectory` function. This trajectory serves as the ground truth for the task.

2. Dataset Creation:
   Two datasets are created from the simulated trajectory:
   - Clean Dataset: Created using `create_clean_dataset`, this dataset contains pairs of consecutive states (current state, next state) from the ground truth trajectory.
   - Noisy Dataset: Created using `create_noisy_dataset`, this dataset contains pairs of noisy states and their corresponding clean states. The noisy states are generated by adding random Gaussian noise to the clean states. Multiple noisy samples are generated for each clean sample to cover a wider range of the noise distribution.

3. Model Architectures:
   - Behavior Cloning MLP: A simple multilayer perceptron (MLP) model is used for behavior cloning. It takes the current state as input and predicts the next state.
   - Denoising Autoencoder: An autoencoder model with an encoder and a decoder is used for denoising. It takes the concatenation of the noisy current state and the noisy next state as input and outputs the denoised current state and the denoised next state.

4. Training:
   - Behavior Cloning: The MLP model is trained using the clean dataset, minimizing the mean squared error (MSE) between the predicted next state and the ground truth next state.
   - Denoising Autoencoder: The denoising autoencoder is trained using the noisy dataset, minimizing the MSE between the denoised outputs and the corresponding clean states.

5. Trajectory Generation and Visualization:
   Three trajectories are generated and visualized:
   - Ground Truth Trajectory: The original simulated trajectory.
   - Behavior Cloning Trajectory: Generated by recursively applying the behavior cloning MLP model on the previous state.
   - Denoised Behavior Cloning Trajectory: Generated by applying the behavior cloning MLP model on the denoised state from the previous step, and then denoising the output using the denoising autoencoder.

The main goal of this experiment is to demonstrate how the denoising autoencoder can help mitigate the covariate shift issue in behavior cloning by denoising the outputs of the behavior cloning model, leading to a trajectory that is closer to the ground truth.

Note: This experiment assumes a simple 2D trajectory tracking task. In more complex scenarios, additional techniques or modifications may be required to handle the covariate shift issue effectively.
"""

import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader

# Simulate a simple 2D sinusoidal trajectory
def simulate_trajectory(num_samples, amplitude=1.0, freq=1.0, random_sampling=False):
    """
    Simulate a simple 2D sinusoidal trajectory with optional random time steps.

    Args:
        num_samples (int): The number of samples in the trajectory.
        amplitude (float, optional): The amplitude of the sinusoidal curve. Default is 1.0.
        freq (float, optional): The frequency of the sinusoidal curve. Default is 1.0.
        random_sampling (bool, optional): Whether to use random sampling for time steps. Default is False.

    Returns:
        np.ndarray: A 2D array representing the simulated trajectory, where each row is a (x, y, x_next, y_next) coordinate.
    """
    trajectory = []

    if random_sampling:
        for _ in range(num_samples):
            x = np.random.uniform(0, 2 * np.pi)
            y = amplitude * np.sin(freq * x)
            dt = np.random.uniform(0.09, 0.11)
            x_next = x + dt
            y_next = amplitude * np.sin(freq * x_next)
            trajectory.append((x, y, x_next, y_next))
    else:
        t = np.linspace(0, 2 * np.pi, num_samples + 1)[:-1]
        x = t
        y = amplitude * np.sin(freq * t)
        x_next = t + 0.1
        y_next = amplitude * np.sin(freq * x_next)
        trajectory = np.column_stack((x, y, x_next, y_next))

    return np.array(trajectory)

def create_clean_dataset(trajectory):
    """
    Create a dataset from the simulated trajectory.

    Args:
        trajectory (np.ndarray): The simulated trajectory.

    Returns:
        tuple: A tuple containing two numpy arrays (X, Y), where X is the input data (current states)
               and Y is the output data (next states).
    """
    X = trajectory[:, :2]
    Y = trajectory[:, 2:]
    return X, Y

# Create a augment dataset from the clean data (adding noise to current state)
def create_augment_dataset(X, Y, noise_factor=0.1, num_noisy_samples=10):
    X_aug, Y_aug = [], []
    for x, y in zip(X, Y):
        for _ in range(num_noisy_samples):
            noise_x = noise_factor * np.random.normal(loc=0.0, scale=1.0, size=2)
            noisy_x = x + noise_x
            X_aug.append(noisy_x)
            Y_aug.append(y)
    return np.array(X_aug), np.array(Y_aug)

# Create a denoisingAE dataset from the clean data
def create_denoisingAE_dataset(X, Y, noise_factor=[0.1, 0.1], num_noisy_samples=10):
    # input X is the concat of noisy version of current state and next state
    # output Y is the concat of clearn version of current state and next state
    X_noisy, Y_noisy = [], []
    for x, y in zip(X, Y):
        for _ in range(num_noisy_samples):
            noise_x = noise_factor[0] * np.random.normal(loc=0.0, scale=1.0, size=2)
            noise_y = noise_factor[1] * np.random.normal(loc=0.0, scale=1.0, size=2)
            noisy_x = x + noise_x
            noisy_y = y + noise_y
            X_noisy.append(np.concatenate((noisy_x, noisy_y)))
            Y_noisy.append(np.concatenate((x, y)))
    return np.array(X_noisy), np.array(Y_noisy)

# Define the MLP model for behavior cloning
class BehaviorCloningMLP(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(BehaviorCloningMLP, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Define the denoising autoencoder
class DenoisingAutoencoder(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(DenoisingAutoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, output_size)
        )
        self.decoder = nn.Sequential(
            nn.Linear(output_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, input_size)
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        denoised_current_state, denoised_next_state = torch.split(decoded, [x.shape[1] - 2, 2], dim=1)
        return denoised_current_state, denoised_next_state

# Train the MLP using behavior cloning
def train_behavior_cloning(X, Y, num_epochs=100, batch_size=32, hidden_size=64):
    X_tensor = torch.tensor(X, dtype=torch.float32)
    Y_tensor = torch.tensor(Y, dtype=torch.float32)
    dataset = TensorDataset(X_tensor, Y_tensor)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    input_size = X.shape[-1]
    output_size = Y.shape[-1]
    model = BehaviorCloningMLP(input_size, hidden_size, output_size)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters())

    for epoch in range(num_epochs):
        for inputs, targets in dataloader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()

        if (epoch + 1) % 2 == 0:
            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')

    return model

# Train the denoising autoencoder
def train_denoising_autoencoder(X_noisy, Y_noisy, num_epochs=100, batch_size=32, hidden_size=64):
    X_noisy_tensor = torch.tensor(X_noisy, dtype=torch.float32)
    Y_noisy_tensor = torch.tensor(Y_noisy, dtype=torch.float32)

    dataset = TensorDataset(X_noisy_tensor, Y_noisy_tensor)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    input_size = X_noisy.shape[-1]
    output_size = Y_noisy.shape[-1] // 2
    model = DenoisingAutoencoder(input_size, hidden_size, output_size)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters())

    for epoch in range(num_epochs):
        for inputs, targets in dataloader:
            optimizer.zero_grad()
            denoised_current_state, denoised_next_state = model(inputs)
            denoised_outputs = torch.cat([denoised_current_state, denoised_next_state], dim=1)
            loss = criterion(denoised_outputs, targets)
            loss.backward()
            optimizer.step()

        if (epoch + 1) % 2 == 0:
            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')

    return model

# Visualize the trajectories
def visualize_trajectories(bc_model, denoising_model, bc_augment_model, ground_truth, initial_state, num_steps):
    ground_truth_trajectory = ground_truth
    bc_trajectory = [initial_state]
    bc_augment_trajectory = [initial_state]
    denoised_trajectory = [initial_state]

    bc_state = torch.tensor(initial_state, dtype=torch.float32).unsqueeze(0)
    bc_augment_state = torch.tensor(initial_state, dtype=torch.float32).unsqueeze(0)
    denoised_state = torch.tensor(initial_state, dtype=torch.float32).unsqueeze(0)

    with torch.no_grad():
        for _ in range(num_steps - 1):
            # Generate behavior cloning trajectory
            bc_next_state = bc_model(bc_state)
            bc_trajectory.append(bc_next_state.squeeze().numpy())
            bc_state = bc_next_state
            
            # Generate behavior cloning trajectory with noisy X
            bc_augment_next_state = bc_augment_model(bc_augment_state)
            bc_augment_trajectory.append(bc_augment_next_state.squeeze().numpy())
            bc_augment_state = bc_augment_next_state

            # Generate denoised trajectory
            bc_next_state_from_denoised = bc_model(denoised_state)
            print(f"step{_}: bc_next_state_from_denoised={bc_next_state_from_denoised}")
            # # Add perturbation noise to the denoising input
            # noise_factor = 0.05
            # noise = noise_factor * torch.randn_like(bc_next_state_from_denoised)
            denoising_input = torch.cat([denoised_state, bc_next_state_from_denoised], dim=1)
            denoised_current_state, denoised_next_state = denoising_model(denoising_input)
            print(f"step{_}: denoised_current_state={denoised_current_state}; denoised_next_state={denoised_next_state}")
            denoised_trajectory.append(denoised_next_state.squeeze().numpy())
            denoised_state = denoised_next_state

    bc_trajectory = np.array(bc_trajectory)
    print(f"bc_trajectory: {bc_trajectory}")
    bc_augment_trajectory = np.array(bc_augment_trajectory)
    print(f"bc_augment_trajectory: {bc_augment_trajectory}")
    denoised_trajectory = np.array(denoised_trajectory)
    print(f"denoised_tratectory: {denoised_trajectory}")

    plt.figure(figsize=(8, 6))
    plt.scatter(ground_truth_trajectory[:, 0], ground_truth_trajectory[:, 1], marker='o', s=10, label='Ground Truth')
    plt.plot(bc_trajectory[:, 0], bc_trajectory[:, 1], label='Behavior Cloning')
    plt.plot(bc_augment_trajectory[:, 0], bc_augment_trajectory[:, 1], label='Behavior Cloning with noisy input')
    plt.plot(denoised_trajectory[:, 0], denoised_trajectory[:, 1], label='Denoised Behavior Cloning')
    plt.xlabel('X')
    plt.ylabel('Y')
    plt.title('Trajectories Comparison')
    plt.legend()
    plt.show()

# Example usage
random_sampling = True
num_steps = 100
ground_truth = simulate_trajectory(num_steps, random_sampling=random_sampling, freq=2.5)
X_clean, Y_clean = create_clean_dataset(ground_truth)
X_denoisingAE, Y_denoisingAE = create_denoisingAE_dataset(X_clean, Y_clean, num_noisy_samples=50)
X_augment, Y_augment = create_augment_dataset(X_clean, Y_clean, noise_factor=0.1, num_noisy_samples=50)
print(f"X_noisy: {X_denoisingAE}; Y_noisy: {Y_denoisingAE}")
bc_model = train_behavior_cloning(X_clean, Y_clean)
bc_augment_model = train_behavior_cloning(X_augment, Y_augment)
denoising_model = train_denoising_autoencoder(X_denoisingAE, Y_denoisingAE, num_epochs=40)

initial_state = ground_truth[0][:2] * 0.01
visualize_trajectories(bc_model, denoising_model, bc_augment_model, ground_truth, initial_state, num_steps=num_steps)

